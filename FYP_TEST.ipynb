{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dependences model traing code :\n",
        "\n",
        "\n",
        "Traing the model to only predict the first column:\n",
        "Stage 1"
      ],
      "metadata": {
        "id": "uKsm0Bj5Iui1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets transformers rouge-score nltk\n",
        "#!pip install evaluate\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"/content/dataset_FYP.xlsx\"\n",
        "\n",
        "# Load Excel file\n",
        "df = pd.read_excel(file_path, engine='openpyxl')\n",
        "df=df[[\"Question statment\",\"Characters\",\"States\",\"Start State\",\"Transitions\",\"Final States\"]]\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n",
        "df[\"Question statment\"]=df[\"Question statment\"].str.replace('\"', ' ')\n",
        "df[\"Characters\"]=df[\"Characters\"].str.replace('\"', '').str.strip()\n",
        "df[\"States\"]=df[\"States\"].str.replace('\"', '').str.strip()\n",
        "df[\"Start State\"]=df[\"Start State\"].str.replace('\"', '').str.strip()\n",
        "df[\"Transitions\"]=df[\"Transitions\"].str.replace('\"', '').str.strip()\n",
        "df[\"Final States\"]=df[\"Final States\"].str.replace('\"', '').str.strip()\n",
        "\n",
        "\n",
        "\n",
        "df[\"States\"] = df[\"States\"].str.replace(\" \", \"\").str.replace(\"{\", \"\").str.replace(\"}\", \"\")\n",
        "df[\"States\"] = \"{\" + df[\"States\"] + \"}\"\n",
        "stage_1=df[[\"Question statment\",\"Characters\"]]\n",
        "\n",
        "stage_1 = df[[\"Question statment\", \"Characters\"]].dropna()\n",
        "stage_1 = stage_1[(stage_1[\"Question statment\"].str.strip() != \"\") & (stage_1[\"Characters\"].str.strip() != \"\")]\n",
        "\n",
        "stage_1 = stage_1.rename(columns={\n",
        "    \"Question statment\": \"input_text\",\n",
        "    \"Characters\": \"target_text\"\n",
        "})\n",
        "\n",
        "\n",
        "dataset1 = Dataset.from_pandas(stage_1)\n",
        "\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "def preprocess(example):\n",
        "    model_input = tokenizer(\"Predict characters: \" + example[\"input_text\"],\n",
        "                            truncation=True, padding=\"max_length\", max_length=64)\n",
        "    target = tokenizer(example[\"target_text\"],\n",
        "                       truncation=True, padding=\"max_length\", max_length=16)\n",
        "    model_input[\"labels\"] = target[\"input_ids\"]\n",
        "    return model_input\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_dataset1 = dataset1.map(preprocess)\n",
        "\n",
        "\n",
        "split = tokenized_dataset1.train_test_split(test_size=0.1,shuffle=True,seed=42)\n",
        "train_dataset = split[\"train\"]\n",
        "eval_dataset = split[\"test\"]\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    predictions, labels = eval_preds\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_preds = [p.strip() for p in decoded_preds]\n",
        "    decoded_labels = [l.strip() for l in decoded_labels]\n",
        "    return {\"accuracy\": accuracy_score(decoded_labels, decoded_preds)}\n",
        "\n",
        "\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./t5_stage1_model\",\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=30,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",            # <-- Log every epoch\n",
        "    logging_dir=\"./logs\",\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"tensorboard\"              # <-- Enables TensorBoard logging\n",
        ")\n",
        "\n",
        "# Step 6: Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    compute_metrics=compute_metrics,     # <-- Include accuracy metric\n",
        ")\n",
        "\n",
        "# Step 7: Train\n",
        "trainer.train()\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "CA3ZfmibHlLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOJKV0HzUMAT"
      },
      "outputs": [],
      "source": [
        "#!unzip -q t5_stage1_model.zip -d t5_stage1_model/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the stage 1 predictions"
      ],
      "metadata": {
        "id": "7RE9xuxQJkCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzSv1pYVtBBy",
        "outputId": "7755deda-7514-416d-937f-cbfc98c23591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Characters: {0,1}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load trained model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/T5_stage1_model\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# Set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Example test input (similar format to your \"Question statement\")\n",
        "input_question = \"Strings of length atleast 3\"\n",
        "\n",
        "# Prepare input for model\n",
        "input_text = \"Predict characters: \" + input_question\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Generate prediction\n",
        "output_ids = model.generate(input_ids, max_length=30, num_beams=4, early_stopping=True)\n",
        "\n",
        "# Decode output\n",
        "predicted_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Predicted Characters:\", \"{\"+predicted_text+\"}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIKx6uzZLr60"
      },
      "source": [
        "### **Stage 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTOb3GBQUKU8"
      },
      "outputs": [],
      "source": [
        "# ===== Step 1: Load & Prepare Data =====\n",
        "df = df[[\"Question statment\", \"States\"]].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467,
          "referenced_widgets": [
            "812fc74e8cba417db2afa7a09268da39",
            "e35dc97a802947d28490e8569640c918",
            "17485a628e2b424caf6ff389b8d99349",
            "ea2d983a66884b7382b7d3288d2d7d8b",
            "d0a673d8c2504927b64c3e922b2ecae4",
            "5b637f968b7946d78739741fc7cea2d0",
            "60680947076b410989326b045d6f19d0",
            "e743e92701b74299b24c9524dd50a5eb",
            "272c8079594a4c448fe3f69e82c57276",
            "1a87c676430e4c41be429f876bf29701",
            "b877ed8e99c84bd8947263c7aeded654"
          ]
        },
        "id": "dn_jA2CCegH1",
        "outputId": "d6c06b5d-1239-440f-89f1-f33000d599f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/507 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "812fc74e8cba417db2afa7a09268da39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3952774681.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2280/2280 2:44:37, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.032900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2280, training_loss=0.10492491847590396, metrics={'train_runtime': 9883.3244, 'train_samples_per_second': 0.923, 'train_steps_per_second': 0.231, 'total_flos': 308579307356160.0, 'train_loss': 0.10492491847590396, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "\n",
        "stage_2 = df.dropna(subset=[\"Question statment\", \"States\"])\n",
        "stage_2 = stage_2[(stage_2[\"Question statment\"].str.strip() != \"\") & (stage_2[\"States\"].str.strip() != \"\")]\n",
        "\n",
        "\n",
        "\n",
        "# ===== Step 2: Create Dataset =====\n",
        "stage_2 = pd.DataFrame({\n",
        "    \"input_text\": stage_2[\"Question statment\"],\n",
        "    \"target_text\": stage_2[\"States\"]\n",
        "})\n",
        "\n",
        "\n",
        "dataset = Dataset.from_pandas(stage_2)\n",
        "\n",
        "# ===== Step 3: Tokenizer & Preprocessing =====\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "def preprocess(example):\n",
        "    model_input = tokenizer(\n",
        "        \"Given the DFA description, list all states in {q0,q1,...} format: \" + example[\"input_text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target = tokenizer(\n",
        "            example[\"target_text\"],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=64\n",
        "        )\n",
        "    model_input[\"labels\"] = target[\"input_ids\"]\n",
        "    return model_input\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess)\n",
        "\n",
        "# ===== Step 4: Train-Test Split =====\n",
        "split = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
        "train_dataset = split[\"train\"]\n",
        "eval_dataset = split[\"test\"]\n",
        "\n",
        "# ===== Step 5: Metrics =====\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    predictions, labels = eval_preds\n",
        "\n",
        "    # Convert model predictions to text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in labels before decoding\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Strip spaces\n",
        "    decoded_preds = [p.strip() for p in decoded_preds]\n",
        "    decoded_labels = [l.strip() for l in decoded_labels]\n",
        "\n",
        "    # Compute accuracy\n",
        "    return {\"accuracy\": accuracy_score(decoded_labels, decoded_preds)}\n",
        "\n",
        "\n",
        "# ===== Step 6: Training Setup =====\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"t5_stage2_model\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=20,  # More epochs since dataset is small\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=1000,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# ===== Step 7: Train =====\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Step 7: Save =====\n",
        "model.save_pretrained(\"t5_stage2_model\")\n",
        "tokenizer.save_pretrained(\"t5_stage2_model\")"
      ],
      "metadata": {
        "id": "UZmgKP1E3DN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "AV8J0fZ0c-QS",
        "outputId": "36918039-97dc-4c4c-a6cd-0388a6368422"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:35]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.0283698458224535, 'eval_accuracy': 0.19047619047619047, 'eval_runtime': 45.8562, 'eval_samples_per_second': 0.458, 'eval_steps_per_second': 0.131, 'epoch': 10.0}\n"
          ]
        }
      ],
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trying the fold Method for stage 2**"
      ],
      "metadata": {
        "id": "Ga9NVQegKuwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b34fa049abe04d088c9979b905765464",
            "e3478ef2a76645eb937fbe265a2e63ea",
            "acc73b397392447c963a1eefd1b697eb",
            "ed37928829be4e659bc8b3abd4a4fe4e",
            "684b8f473a49457697c00dbc6f9b82d1",
            "10c947b2d58c41328a0a193b9d30c2d9",
            "4b3a67128995409d86f5c64979d7cd74",
            "dd90fce5d0c64bed868d690574fef4ff",
            "559c427da7b44582900a1f96213020b9",
            "e35aa68aa1fd405080d7438d8fd3216e",
            "54d4e3e59bfa485d896a715076bd3d93"
          ]
        },
        "id": "xb7fsgNuBUPq",
        "outputId": "2b576ab0-8d9c-41f0-e791-5b6a35cc9b4e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b34fa049abe04d088c9979b905765464",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/201 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Fold 1 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4040990956.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkareembutt42\u001b[0m (\u001b[33mkareembutt42-university-of-central-punjab\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250817_171429-incy7xsj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kareembutt42-university-of-central-punjab/huggingface/runs/incy7xsj' target=\"_blank\">rosy-voice-9</a></strong> to <a href='https://wandb.ai/kareembutt42-university-of-central-punjab/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/kareembutt42-university-of-central-punjab/huggingface' target=\"_blank\">https://wandb.ai/kareembutt42-university-of-central-punjab/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/kareembutt42-university-of-central-punjab/huggingface/runs/incy7xsj' target=\"_blank\">https://wandb.ai/kareembutt42-university-of-central-punjab/huggingface/runs/incy7xsj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 21:33, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 Accuracy: 0.36585365853658536\n",
            "\n",
            "===== Fold 2 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4040990956.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='410' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [410/410 21:42, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:16]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2 Accuracy: 0.325\n",
            "\n",
            "===== Fold 3 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4040990956.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='410' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [410/410 21:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:16]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3 Accuracy: 0.4\n",
            "\n",
            "===== Fold 4 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4040990956.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='410' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [410/410 21:31, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4 Accuracy: 0.25\n",
            "\n",
            "===== Fold 5 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4040990956.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='410' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [410/410 21:37, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:16]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 5 Accuracy: 0.225\n",
            "\n",
            "Average Accuracy: 0.3131707317073171\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ===== Load & Clean Data =====\n",
        "df = pd.read_excel(\"/content/dataset_FYP.xlsx\")  # Replace with your dataset path\n",
        "df = df.dropna(subset=[\"Question statment\", \"States\"])\n",
        "df = df[(df[\"Question statment\"].str.strip() != \"\") & (df[\"States\"].str.strip() != \"\")]\n",
        "\n",
        "# Create Hugging Face Dataset\n",
        "hf_dataset = Dataset.from_pandas(pd.DataFrame({\n",
        "    \"input_text\": df[\"Question statment\"],\n",
        "    \"target_text\": df[\"States\"]\n",
        "}))\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess(example):\n",
        "    model_input = tokenizer(\n",
        "        \"Given the DFA description, list all states in {q0,q1,...} format: \" + example[\"input_text\"],\n",
        "        truncation=True, padding=\"max_length\", max_length=128\n",
        "    )\n",
        "    target = tokenizer(\n",
        "        example[\"target_text\"],\n",
        "        truncation=True, padding=\"max_length\", max_length=64\n",
        "    )\n",
        "    model_input[\"labels\"] = target[\"input_ids\"]\n",
        "    return model_input\n",
        "\n",
        "# Pre-tokenize dataset\n",
        "tokenized_dataset = hf_dataset.map(preprocess)\n",
        "\n",
        "# Accuracy function\n",
        "def compute_metrics(eval_preds):\n",
        "    predictions, labels = eval_preds\n",
        "    predictions = predictions.argmax(-1) if predictions.ndim == 3 else predictions\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    return {\"accuracy\": accuracy_score([l.strip() for l in decoded_labels],\n",
        "                                       [p.strip() for p in decoded_preds])}\n",
        "\n",
        "# ===== K-Fold Cross Validation =====\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(tokenized_dataset)):\n",
        "    print(f\"\\n===== Fold {fold+1} =====\")\n",
        "\n",
        "    train_dataset = tokenized_dataset.select(train_idx)\n",
        "    eval_dataset = tokenized_dataset.select(val_idx)\n",
        "\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=f\"t5_stage2_fold{fold+1}\",\n",
        "        learning_rate=5e-5,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        num_train_epochs=10,\n",
        "        weight_decay=0.01,\n",
        "        predict_with_generate=True,\n",
        "        logging_dir=f\"./logs_fold{fold+1}\",\n",
        "        save_total_limit=1\n",
        "    )\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(f\"Fold {fold+1} Accuracy:\", metrics[\"eval_accuracy\"])\n",
        "    fold_results.append(metrics[\"eval_accuracy\"])\n",
        "\n",
        "# ===== Final Average Accuracy =====\n",
        "print(\"\\nAverage Accuracy:\", sum(fold_results)/len(fold_results))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10c947b2d58c41328a0a193b9d30c2d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3a67128995409d86f5c64979d7cd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d4e3e59bfa485d896a715076bd3d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "559c427da7b44582900a1f96213020b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "684b8f473a49457697c00dbc6f9b82d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc73b397392447c963a1eefd1b697eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd90fce5d0c64bed868d690574fef4ff",
            "max": 201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_559c427da7b44582900a1f96213020b9",
            "value": 201
          }
        },
        "b34fa049abe04d088c9979b905765464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3478ef2a76645eb937fbe265a2e63ea",
              "IPY_MODEL_acc73b397392447c963a1eefd1b697eb",
              "IPY_MODEL_ed37928829be4e659bc8b3abd4a4fe4e"
            ],
            "layout": "IPY_MODEL_684b8f473a49457697c00dbc6f9b82d1"
          }
        },
        "dd90fce5d0c64bed868d690574fef4ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3478ef2a76645eb937fbe265a2e63ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10c947b2d58c41328a0a193b9d30c2d9",
            "placeholder": "​",
            "style": "IPY_MODEL_4b3a67128995409d86f5c64979d7cd74",
            "value": "Map: 100%"
          }
        },
        "e35aa68aa1fd405080d7438d8fd3216e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed37928829be4e659bc8b3abd4a4fe4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35aa68aa1fd405080d7438d8fd3216e",
            "placeholder": "​",
            "style": "IPY_MODEL_54d4e3e59bfa485d896a715076bd3d93",
            "value": " 201/201 [00:00&lt;00:00, 764.43 examples/s]"
          }
        },
        "812fc74e8cba417db2afa7a09268da39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e35dc97a802947d28490e8569640c918",
              "IPY_MODEL_17485a628e2b424caf6ff389b8d99349",
              "IPY_MODEL_ea2d983a66884b7382b7d3288d2d7d8b"
            ],
            "layout": "IPY_MODEL_d0a673d8c2504927b64c3e922b2ecae4"
          }
        },
        "e35dc97a802947d28490e8569640c918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b637f968b7946d78739741fc7cea2d0",
            "placeholder": "​",
            "style": "IPY_MODEL_60680947076b410989326b045d6f19d0",
            "value": "Map: 100%"
          }
        },
        "17485a628e2b424caf6ff389b8d99349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e743e92701b74299b24c9524dd50a5eb",
            "max": 507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_272c8079594a4c448fe3f69e82c57276",
            "value": 507
          }
        },
        "ea2d983a66884b7382b7d3288d2d7d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a87c676430e4c41be429f876bf29701",
            "placeholder": "​",
            "style": "IPY_MODEL_b877ed8e99c84bd8947263c7aeded654",
            "value": " 507/507 [00:00&lt;00:00, 1224.66 examples/s]"
          }
        },
        "d0a673d8c2504927b64c3e922b2ecae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b637f968b7946d78739741fc7cea2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60680947076b410989326b045d6f19d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e743e92701b74299b24c9524dd50a5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "272c8079594a4c448fe3f69e82c57276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a87c676430e4c41be429f876bf29701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b877ed8e99c84bd8947263c7aeded654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}